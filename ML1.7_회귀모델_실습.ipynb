{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3537e6a",
   "metadata": {},
   "source": [
    "## 회귀 (regression) 예측\n",
    "\n",
    "수치형 값을 예측(Y의 값이 연속된 수치로 표현)\n",
    "\n",
    "#### 예시\n",
    "- 주택 가격 예측\n",
    "- 매출액 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c8638c",
   "metadata": {},
   "source": [
    "## 평가 지표 만들기\n",
    "\n",
    "### MSE(Mean Squared Error)\n",
    "예측값과 실제값의 차이에 대한 제곱에 대해 평균을 낸 값\n",
    "\n",
    "### MAE(Mean Absolute Error)\n",
    "예측값과 실제값의 차이에 대한 절대값에 대하여 평균을 낸 값\n",
    "\n",
    "### RMSE(Root Mean Squared Error)\n",
    "예측값과 실제값의 차이에 대한 제곱에 대해 평균을 낸 뒤 루트를 씌운 값|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56533caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2ba811",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([3, 4, 5])\n",
    "actual = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1f3f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_mse(pred, actual):\n",
    "    return ((pred - actual)**2).mean()\n",
    "my_mse(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e59f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_mae(pred, actual):\n",
    "    return np.abs(pred-actual).mean()\n",
    "my_mae(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e5cdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_rmse(pred, actual):\n",
    "    return np.sqrt(my_mse(pred, actual))\n",
    "my_rmse(pred, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eac806",
   "metadata": {},
   "source": [
    "### sklearn의 평가지표 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ccffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9eca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 2.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mae(pred, actual), mean_absolute_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fca3702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 4.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mse(pred, actual), mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e02a1",
   "metadata": {},
   "source": [
    "### 모델별 성능 확인을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c26d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_predictions = {}\n",
    "\n",
    "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
    "         'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
    "         'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive',\n",
    "         'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocoloate',\n",
    "         'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray',\n",
    "         'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato']\n",
    "\n",
    "def plot_predictions(name_, pred, actual):\n",
    "    df = pd.DataFrame({'prediction':pred, 'actual':y_test})\n",
    "    df = df.sort_values(by='actual').reset_index(drop=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.scatter(df.index, df['prediction'], marker='x', color='r')\n",
    "    plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black')\n",
    "    plt.title(name_, fontsize=15)\n",
    "    plt.legend(['prediction', 'actual'], fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "def mse_eval(name_, pred, actual):\n",
    "    global predictions\n",
    "    global colors\n",
    "    \n",
    "    plot_predictions(name_, pred, actual)\n",
    "    \n",
    "    mse = mean_squared_error(pred, actual)\n",
    "    my_prediction[name_] = mse\n",
    "    \n",
    "    y_value = sorted(my_predictions.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'mse'])\n",
    "    print(df)\n",
    "    min_ = df['mse'].min() - 10\n",
    "    max_ = df['mse'].max() + 10\n",
    "    \n",
    "    length = len(df)\n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['mse'])\n",
    "    \n",
    "    for i, v in enumerate(df['mse']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v+2, i, str(round(v,3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "        \n",
    "    plt.title('MSE Error', fontsize=18)\n",
    "    plt.xlim(min_, max_)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def remove_model(name_):\n",
    "    global my_predictions\n",
    "    try:\n",
    "        del my_predictions[name_]\n",
    "    except KeyError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47760417",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1dd87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a98380",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f574b496",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train\u001b[49m, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36dec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
